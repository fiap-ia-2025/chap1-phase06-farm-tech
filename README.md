# FIAP - Faculdade de InformÃ¡tica e AdministraÃ§Ã£o Paulista

<p align="center">
  <a href="https://www.fiap.com.br/">
    <img src="img/logo-fiap.png" alt="FIAP - Faculdade de InformÃ¡tica e AdministraÃ§Ã£o Paulista" border="0" width="80%" height="40%">
  </a>
</p>

## ğŸ‘¥ Grupo 25

## ğŸ‘¨â€ğŸ“ Integrantes:

- Amanda Vieira Pires (RM566330)
- Ana Gabriela Soares Santos (RM565235)
- Bianca Nascimento de Santa Cruz Oliveira (RM561390)
- Milena Pereira dos Santos Silva (RM565464)
- Nayana Mehta Miazaki (RM565045)

## ğŸ‘©â€ğŸ« Professores:

### Tutor(a)

- Lucas Gomes Moreira

### Coordenador(a)

- AndrÃ© Godoi

---

# **ENTREGA 1** ğŸŒ¾ FarmTech Solutions - Projeto de IA para Agricultura

## ğŸ“‹ Sobre o Projeto

O **FarmTech Solutions** Ã© um projeto de InteligÃªncia Artificial desenvolvido para a **Fase 6 do curso de InteligÃªncia Artificial da FIAP**. 
Com o sucesso da implementaÃ§Ã£o de soluÃ§Ãµes de IA para a otimizaÃ§Ã£o de plantaÃ§Ãµes, a FarmTech Solutions expandiu sua atuaÃ§Ã£o para alÃ©m do agronegÃ³cio tradicional, abrangendo agora o setor de **saÃºde animal** e outros serviÃ§os estratÃ©gicos. O projeto visa a implementaÃ§Ã£o do **mÃ©todo YOLO** para detectar e segregar objetos a fim de criar um sistema de visÃ£o computacional eficaz para uma anÃ¡lise prÃ¡tica e em tempo real, fornecendo insights acionÃ¡veis para otimizar a produtividade e garantir o melhor cuidado para seu rebanho, unindo o sucesso que jÃ¡ obtivemos no campo com a inovaÃ§Ã£o no **manejo animal**. 

### ğŸ¯ Objetivos

- **Dataset**: seleÃ§Ã£o de imagens separadas em treinamento, validaÃ§Ã£o e teste.
- **Labels**: criaÃ§Ã£o de labels nas imagens para identificaÃ§Ã£o dos objetos
- **Arquitetura**: YOLO

### ğŸ“Š Dataset

**Pasta**: Cap_1
**Local**: Google drive
**Link**: https://drive.google.com/drive/folders/1WLe_Iwy2RCa5MSCHE2sDJgeLfuxUh-B9?usp=drive_link

# ğŸ—ï¸ Estrutura do Projeto

```
chap1-phase06-farm-tech/
â”œâ”€â”€ FarmTech_Solutions_YOLO.ipynb  # Google colab notebook
â””â”€â”€ README.md                      # Este arquivo
```

# ğŸ”„ Fluxo do Projeto

```
ğŸ¯ Dataset â†’ ğŸ”€ DetecÃ§Ã£o e SegmentaÃ§Ã£o 
```

# Etapas Principais

**1. ğŸ¯ Dataset** (Make sense IA: 2 labels)

**2. ğŸ”€ Arquitetura** (YOLO)

# ğŸš€ Como Executar

## 1. **PrÃ©-requisitos**

- Google Colab Notebook
- Google Drive
- Git

## 2. **InstalaÃ§Ã£o**

```bash
# Clone o repositÃ³rio
git clone https://github.com/fiap-ia-2025/chap1-phase06-farm-tech.git
```

# 3. **ExecuÃ§Ã£o**

1. CriaÃ§Ã£o do Dataset no GoogleDrive: necessÃ¡rio clonar as pastas do Google Drive para seu prÃ³prio Drive.
2. Executar cÃ³digo do Google Colab Notebook

# ğŸ› ï¸ Tecnologias e DependÃªncias

## Tecnologias Utilizadas

- **Google Colab Notebook**: Ambiente de desenvolvimento
- **Google drive**: Armazenamento dados

# ğŸ“Š Dataset

Para iniciar o desenvolvimento do sistema de visÃ£o computacional, foram selecionados dois objetos principais: `Sheep` (Ovelha) e `Cow` (Vaca). <br>
A plataforma `Make Sense IA` foi utilizada para a crucial etapa de rotulagem (labeling). Neste processo, as imagens de ovelhas e vacas foram inseridas para que os labels fossem criados e, subsequentemente, identificados com precisÃ£o em cada imagem. Isso Ã© fundamental para treinar o modelo a reconhecer cada animal. <br>

Para garantir um treinamento robusto e uma avaliaÃ§Ã£o justa do modelo, foi separado um total de 40 imagens para cada animal. O conjunto de dados foi entÃ£o dividido e organizado em pastas definidas no `Google Drive`, seguindo a distribuiÃ§Ã£o padrÃ£o para aprendizado de mÃ¡quina: <br>

**Treino**: 32 imagens (para o treinamento do modelo). <br>

**ValidaÃ§Ã£o**: 4 imagens (para ajuste fino do modelo durante o treinamento). <br>

**Teste**: 4 imagens (para avaliaÃ§Ã£o do desempenho final do modelo). 

# ğŸ“ˆ AnÃ¡lise e ExplicaÃ§Ã£o do CÃ³digo

O objetivo Ã© treinar o modelo para identificar os objetos `cow` (vaca) e `sheep` (ovelha) utilizando a arquitetura YOLOv5 (You Only Look Once, versÃ£o 5) no ambiente Google Colab.

## 1. âš™ï¸ ConexÃ£o com o Google Drive

Os dados de treinamento (imagens e rÃ³tulos) estÃ£o armazenados na conta do Google Drive e por isso Ã© necessÃ¡ria a sua conexÃ£o.

## 2. â¬‡ï¸ Baixar o RepositÃ³rio YOLOv5 e Instalar DependÃªncias 

O **YOLOv5** Ã© um modelo de detecÃ§Ã£o de objetos de cÃ³digo aberto, portanto Ã© possÃ­vel baixar os arquivos da arquitetura e instalar todas as bibliotecas Python necessÃ¡rias para que o treinamento e a detecÃ§Ã£o funcionem corretamente.

## 3. ğŸ“„ ConfiguraÃ§Ã£o do Dataset

Para informar ao **YOLOv5** onde encontrar os conjuntos de imagens e quais classes (objetos) ele deve aprender a identificar Ã© preciso criar um arquivo de configuraÃ§Ã£o: `data.yaml`.

## 4. ğŸ§  Treinamento do Modelo

O treinamento ocorre em duas fases, usando diferentes nÃºmeros de Ã©pocas, **30 Ã©pocas e 60 Ã©pocas**, para que o modelo aprenda a detectar os objetos.

| MÃ©trica | 30 Ã‰pocas | 60 Ã‰pocas | ComparaÃ§Ã£o |  
| :--- | :---: | ---: | ---: |
| mAP@0.5 | 81,7% | 86,4% | A precisÃ£o na identificaÃ§Ã£o dos objetos melhorou. |
| mAP@0.5:0.95 | 46,5% | 55,1% | A precisÃ£o na localizaÃ§Ã£o exata das caixas delimitadoras teve um avanÃ§o. |
| PrecisÃ£o | 81,7% | 87,6% | Pouca mudanÃ§a na taxa de acertos, porÃ©m ambas estÃ£o altas. |
| Recall | 80% | 84% | Melhoria de 4% para encontrar os objetos reais no conjunto de validaÃ§Ã£o. |
| Loss Final | 0.0247 | 0.0163 | O valor de erros diminuiu, ou seja, o modelo aprendeu a cometer menos erros. |

**Para o treinamento de 60 Ã‰pocas:**

![HistÃ³rico de ExecuÃ§Ã£o](img/historico.jpg)

O grÃ¡fico apresentado Ã© o HistÃ³rico de ExecuÃ§Ã£o gerado durante o treinamento do modelo de VisÃ£o Computacional **YOLOv5**, que tem como objetivo detectar `Cow` (Vaca) e `Sheep `(Ovelha) e verificar a evoluÃ§Ã£o e a saÃºde do modelo ao longo das Ã©pocas de treinamento. <br>

As `metrics/mAP_0.5`, `metrics/mAP_0.5:0.95`, `metrics/precision` e `metrics/recall` sÃ£o **mÃ©tricas de performance** para indicar a capacidade do modelo de acertar as detecÃ§Ãµes do conjunto de validaÃ§Ã£o. A tendÃªncia clara de crescimento nessas barras aponta para um aprendizado bem-sucedido. <br>

As `train/box_loss`, `val/box_loss`, `train/cls_loss`, `val/cls_loss`, `train/obj_loss` e `val/obj_loss` sÃ£o **mÃ©tricas de perda** para mostrar o grau de erro do modelo. A tendÃªncia ideal Ã© a de queda progressiva indicando que o modelo estÃ¡ ajustando seus pesos e diminuindo seus erros a cada Ã©poca.

## 5. âœ… ValidaÃ§Ã£o do Teste

Ocorre a capacidade de detecÃ§Ã£o do modelo, utilizando imagens que ele nunca viu antes.

![Teste Ovelha](img/42.jpg)

![Teste Vaca](img/2.jpg)

As imagens representam o resultado e a eficÃ¡cia do modelo YOLOv5 treinado. As caixas delimitam os animais e os nÃºmeros indicam o nÃ­vel de confianÃ§a da detecÃ§Ã£o do modelo. <br>
Os resultados indicam o sucesso do treinamento com altos nÃ­veis de confianÃ§a na identificaÃ§Ã£o de `cow` e `sheep` em diferentes posiÃ§Ãµes, raÃ§as e ambientes.

# ğŸ¬ VÃ­deo 

Link para vÃ­deo do Youtube: https://youtu.be/ASjsuGd0Lrs

---

# **ENTREGA 2** ğŸ”¬ ComparaÃ§Ã£o de MÃ©todos de VisÃ£o Computacional

## ğŸ“‹ Sobre a Entrega 2

A **Entrega 2** expande o projeto FarmTech Solutions com uma **anÃ¡lise comparativa** de diferentes abordagens de visÃ£o computacional. O objetivo Ã© avaliar criticamente trÃªs mÃ©todos distintos para reconhecimento de objetos (vacas e ovelhas), comparando suas performances, facilidade de uso e aplicabilidade prÃ¡tica.

### ğŸ¯ Objetivos da Entrega 2

- **Comparar 3 mÃ©todos**: YOLO Customizado vs YOLO Tradicional vs CNN do Zero
- **Avaliar mÃ©tricas**: Tempo de treinamento, tempo de inferÃªncia, precisÃ£o e facilidade de uso
- **Fornecer recomendaÃ§Ãµes**: Qual mÃ©todo usar em diferentes cenÃ¡rios
- **AnÃ¡lise crÃ­tica**: Pontos fortes e limitaÃ§Ãµes de cada abordagem

### ğŸ”¬ MÃ©todos Analisados

1. **ğŸ¯ YOLO Customizado** (da Entrega 1)
   - Modelo treinado especificamente para vacas e ovelhas
   - Transfer learning com YOLOv5

2. **âš¡ YOLO Tradicional** (Ultralytics)
   - Modelo prÃ©-treinado no dataset COCO
   - Pronto para uso, sem treinamento adicional

3. **ğŸ§  CNN do Zero** (TensorFlow)
   - Rede neural convolucional criada from scratch
   - ClassificaÃ§Ã£o binÃ¡ria: Vaca vs Ovelha

## ğŸ—ï¸ Estrutura da Entrega 2

```bash
ColabNotebooks/
â”œâ”€â”€ Cap_1/ # Dataset YOLO (Entrega 1 e 2)
â”œâ”€â”€ Cap_1_CNN/ # Dataset CNN organizado (Entrega 02)
â”‚ â”œâ”€â”€ train/
â”‚ â”‚ â”œâ”€â”€ cow/ # Imagens de vacas para treino
â”‚ â”‚ â””â”€â”€ sheep/ # Imagens de ovelhas para treino
â”‚ â”œâ”€â”€ val/
â”‚ â”‚ â”œâ”€â”€ cow/ # Imagens de vacas para validaÃ§Ã£o
â”‚ â”‚ â””â”€â”€ sheep/ # Imagens de ovelhas para validaÃ§Ã£o
â”‚ â””â”€â”€ test/
â”‚ â”œâ”€â”€ cow/ # Imagens de vacas para teste
â”‚ â””â”€â”€ sheep/ # Imagens de ovelhas para teste
â”œâ”€â”€ [Entrega02]FarmTech_Comparacao.ipynb # Notebook da Entrega 2
```

## ğŸš€ Como Executar a Entrega 2

### 1. **PrÃ©-requisitos**
- ExecuÃ§Ã£o prÃ©via da **Entrega 1** (YOLO Customizado)
- Google Colab Notebook
- Google Drive com as pastas organizadas

### 2. **Setup dos Dados**
```bash
# 1. Clone as pastas necessÃ¡rias para seu Google Drive:
# - Cap_1 (da Entrega 1)
# - Cap_1_CNN (nova estrutura para CNN)
```
Link do Drive (Com ambas as pastas): https://drive.google.com/drive/u/0/folders/1_wOu8gbT9Kah4gCnpIoYT3CPSlozOLbK

### 3. ExecuÃ§Ã£o
- Conectar Google Drive no Colab
- Executar YOLO Tradicional: AnÃ¡lise com Ultralytics YOLOv8
- Criar e Treinar CNN: Arquitetura personalizada do zero
- Comparar Resultados: AnÃ¡lise comparativa dos 3 mÃ©todos

## ğŸ“Š CritÃ©rios de AvaliaÃ§Ã£o e Resultados

### ğŸ” MÃ©tricas de ComparaÃ§Ã£o

| CritÃ©rio | DescriÃ§Ã£o | YOLO Customizado | YOLO Tradicional | CNN do Zero |
|----------|-----------|------------------|------------------|-------------|
| **â±ï¸ Tempo de Treinamento** | Tempo necessÃ¡rio para treinar | [A coletar] | 0 min (prÃ©-treinado) | [A coletar] |
| **âš¡ Tempo de InferÃªncia** | Velocidade de prediÃ§Ã£o (ms/imagem) | [A coletar] | [A coletar] | [A coletar] |
| **ğŸ¯ PrecisÃ£o/Accuracy** | Taxa de acertos na detecÃ§Ã£o | [A coletar] | [A coletar] | [A coletar] |
| **ğŸ”§ Facilidade de Uso** | Complexidade de implementaÃ§Ã£o | MÃ©dia | Alta | Baixa |
| **ğŸ”„ Flexibilidade** | AdaptaÃ§Ã£o para novos objetos | Alta | Baixa | Alta |
| **ğŸ“± Aplicabilidade** | AdequaÃ§Ã£o para projeto | [A avaliar] | [A avaliar] | [A avaliar] |

### ğŸ“ˆ Estrutura de AnÃ¡lise

**ğŸ” AnÃ¡lise Individual**: Cada mÃ©todo avaliado com mÃ©tricas especÃ­ficas  
**âš–ï¸ ComparaÃ§Ã£o Direta**: Tabela consolidada dos trÃªs mÃ©todos  
**ğŸ¯ RecomendaÃ§Ãµes**: Por cenÃ¡rio (produÃ§Ã£o, pesquisa, educaÃ§Ã£o)  
**ğŸ“ ConclusÃµes**: AnÃ¡lise crÃ­tica e limitaÃ§Ãµes identificadas  

### ğŸ“Š Resultados da ComparaÃ§Ã£o

| MÃ©todo | Accuracy | Tempo InferÃªncia | Facilidade de Uso | Flexibilidade |
|--------|----------|------------------|-------------------|---------------|
| **YOLO Customizado** | **86.4%** | NÃ£o medido | MÃ©dia | Alta |
| **YOLO Tradicional** | 72.9% | 520ms | **Alta** | Baixa |
| **CNN do Zero** | 62.5% | 682ms | Baixa | **Alta** |

### ğŸ¯ Principais Descobertas

**ğŸ† YOLO Customizado - Melhor Performance**
- **86.4% de accuracy** - superior aos demais mÃ©todos
- Treinamento especÃ­fico para vacas/ovelhas foi eficaz
- Recomendado para ambiente de produÃ§Ã£o

**âš¡ YOLO Tradicional - Melhor Praticidade**  
- **ImplementaÃ§Ã£o imediata** sem necessidade de treinamento
- Performance adequada (72.9%) para casos de uso gerais
- Ideal para prototipagem rÃ¡pida e demonstraÃ§Ãµes

**ğŸ§  CNN do Zero - Melhor Controle**
- **Flexibilidade total** na arquitetura
- Performance limitada (62.5%) com modelo simples
- Excelente para fins educacionais e experimentaÃ§Ã£o

### ğŸ’¡ ConclusÃ£o

O **YOLO Customizado** demonstrou superioridade para o caso especÃ­fico de detecÃ§Ã£o de vacas e ovelhas, validando a abordagem de treinamento especializado da FarmTech Solutions. A comparaÃ§Ã£o revelou que modelos especÃ­ficos superam soluÃ§Ãµes genÃ©ricas quando dados adequados estÃ£o disponÃ­veis.

**RecomendaÃ§Ã£o:** Implementar YOLO Customizado para casos de produÃ§Ã£o, mantendo YOLO Tradicional como alternativa para demonstraÃ§Ãµes rÃ¡pidas.





